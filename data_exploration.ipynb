{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce8b88f-b0d6-46a4-8f27-51feac25eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, flow, get_run_logger\n",
    "from prefect.task_runners import SequentialTaskRunner\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ae765-33f0-4c2e-8573-a0ee3f107871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@task()\n",
    "def find_years_to_prep(data_dir) -> list:\n",
    "    uploaded_files = glob.glob(f\"{data_dir}/**/*___complete\", recursive=True)\n",
    "    uploaded_files = [x.replace(\"___complete\", \"\") for x in uploaded_files]\n",
    "    \n",
    "    prepped_files = glob.glob(f\"{data_dir}/**/*___prepped\", recursive=True)\n",
    "    prepped_files = [x.replace(\"___prepped\", \"\") for x in prepped_files]\n",
    "    \n",
    "    return list(set(uploaded_files).difference(set(prepped_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbac726-9953-4e2a-8e53-b0d3aa78ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def open_csv_station_index(filename: Path|str) -> pd.DataFrame:\n",
    "    year = str(filename)[:4]\n",
    "    df = pd.read_csv(filename, low_memory=False) #, dtype=str)\n",
    "    df[['LATITUDE', 'LONGITUDE', 'ELEVATION']] = df[['LATITUDE', 'LONGITUDE', 'ELEVATION']].fillna('missing')\n",
    "    return df.set_index('STATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de47c9-a150-4145-82f4-464e7c53f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def remove_missing_spatial(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes Records with Missing Spatial Data\n",
    "    - If 'NaN' exists, replaces with 'missing'\n",
    "    - Returns dataframe with all 'missing' spatial elements removed\n",
    "    - Why: This is 100x (guestimate) faster than saving a separate csv with this information removed. Quicker to just\n",
    "           run this function when a dataframe with 100% clean spatial data is required\n",
    "    \"\"\"\n",
    "    df = df[['LATITUDE', 'LONGITUDE', 'ELEVATION']] = df[['LATITUDE', 'LONGITUDE', 'ELEVATION']].fillna('missing')\n",
    "    return df[(df['LATITUDE'] != 'missing') & (df['LONGITUDE'] != 'missing') & (df['ELEVATION'] != 'missing')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acb67e-9e9a-458a-bd53-4e3f08493673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@task()\n",
    "def find_missing_lat_long(station_indexed_df: pd.DataFrame, filename: Path|str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    NOTE: Assumes dataframe has had 'nan' replaced with 'missing' string already.\n",
    "    \"\"\"\n",
    "    # FIND RECORDS MISSING LATITUDE OR LONGITUDE (or both)\n",
    "    df = station_indexed_df\n",
    "    df = df[(df['LATITUDE']=='missing') | (df['LONGITUDE']=='missing')]\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    if isinstance(filename, str):\n",
    "        filename = Path(filename)\n",
    "    year = filename.name[:4]  # separated from f-string for clarity\n",
    "    df.to_csv(Path(filename.parent) / f\"{year}_missing_lat_long.csv\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae0445-21d4-46f3-a3d4-1a6c6c050686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@task()\n",
    "def find_missing_elevation(station_indexed_df: pd.DataFrame, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    NOTE: Assumes dataframe has had 'nan' replaced with 'missing' string already.\n",
    "    \"\"\"\n",
    "    # FIND RECORDS MISSING ONLY ELEVATION\n",
    "    # - these could likely still be used\n",
    "    # - may also be able to pull elevation from else where based on latitude and longitude\n",
    "    df = station_indexed_df\n",
    "    df = df[(df['LATITUDE'] != 'missing') & (df['LONGITUDE'] != 'missing') & (df['ELEVATION'] == 'missing')]\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    if isinstance(filename, str):\n",
    "        filename = Path(filename)\n",
    "    year = filename.name[:4]  # separated from f-string for clarity\n",
    "    df.to_csv(Path(filename.parent) / f\"{year}_missing_only_elevation.csv\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52564f8e-3828-4cef-9caf-d897281b2ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@task()\n",
    "def confirm_consistent_spatial_data(station_indexed_df: pd.DataFrame, filename: Path|str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    NOTE: Assumes dataframe has had 'nan' replaced with 'missing' string already.\n",
    "    \"\"\"\n",
    "    # Confirm all stations each has consistent spatial data\n",
    "    # - *drop* records where spatial data is missing\n",
    "    # - only runs after previous tasks for missing spatial data are complete\n",
    "    df = station_indexed_df\n",
    "    station_grouped_df = df.groupby('STATION')[['LATITUDE', 'LONGITUDE', 'ELEVATION']].value_counts() #dropna=False)\n",
    "    if len(station_grouped_df) == len(df.index.unique()):\n",
    "        # run again, but drop records with 'nan' spatial values\n",
    "        # df = df[(df['LATITUDE'] != 'missing') & (df['LONGITUDE'] != 'missing') & (df['ELEVATION'] != 'missing')]\n",
    "        # df = df.reset_index()\n",
    "        return\n",
    "    else:\n",
    "        # TODO: This part doesn't work yet; also haven't had an inconsistencies above either (i.e., \"else\" has never been triggered).\n",
    "        raise ValueError(f'Spatial data for one or more station ids is not consistent in: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd54775-de2b-4a4f-8b82-37152ef909f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def data_clean_complete(filename):\n",
    "    \"\"\"\n",
    "    In prefect flow should \"wait_for\" missing_lat_long, missing_elevation, and confirm_consistent to all be successfully completed\n",
    "    \"\"\"\n",
    "    with open(f\"{filename}___prepped\", 'w'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcdc2e-8831-47f7-ace5-18a224323065",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "@flow(task_runner=SequentialTaskRunner())\n",
    "def main():\n",
    "    logger = get_run_logger()\n",
    "    data_dir = Path('local_data').resolve() / 'global-summary-of-the-day-archive'\n",
    "    \n",
    "    to_process = glob.glob(f\"{data_dir}/**/*_full.csv\", recursive=True)\n",
    "    to_prep = find_years_to_prep(data_dir)\n",
    "\n",
    "    # process_years = tqdm(sorted(to_prep), desc='Cleaning Year Files')\n",
    "    process_years = sorted(to_prep.wait().result())\n",
    "    for filename in process_years:\n",
    "        file_to_prep = f\"{Path(filename).parent / Path(filename).name[:4]}_full.csv\"\n",
    "        logger.info(f\"STARTING {Path(file_to_prep).name}\")\n",
    "        # process_years.set_description(Path(file_to_prep).name)\n",
    "        station_idx_df = open_csv_station_index(file_to_prep)\n",
    "        missing_lat_long = find_missing_lat_long(station_idx_df, file_to_prep)\n",
    "        missing_elevation = find_missing_elevation(station_idx_df, file_to_prep)\n",
    "        # remove_missing_spatial(station_index_df)\n",
    "        consistent = confirm_consistent_spatial_data(station_idx_df, file_to_prep)\n",
    "        data_clean_complete(filename, wait_for=[missing_lat_long, missing_elevation, consistent])\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629cb8da-c987-45c5-9362-902fbdbc2bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
